{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "9dc76e71-ccc1-46c3-af12-17c104c94008",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient shape: (3, 3)\n",
      "Gradient norm: 0.0370\n",
      "Decoder still normalized: True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43fffdf407dc40fc9e60d2e31cc91c5d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Initial average mutual information: 0.0085\n",
      "Final average mutual information: 0.9888\n"
     ]
    }
   ],
   "source": [
    "import jax\n",
    "import jax.numpy as jnp\n",
    "from jax import grad, jit, vmap\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "from functools import wraps\n",
    "import warnings\n",
    "\n",
    "def check_nan_inf(array, name=\"array\"):\n",
    "    \"\"\"Check if array contains NaN or Inf values.\"\"\"\n",
    "    has_nan = jnp.any(jnp.isnan(array))\n",
    "    has_inf = jnp.any(jnp.isinf(array))\n",
    "    if has_nan or has_inf:\n",
    "        warnings.warn(f\"{name} contains NaN: {has_nan}, Inf: {has_inf}\")\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "def validate_probability_matrix(P, name=\"matrix\", axis=None, tolerance=1e-6):\n",
    "    \"\"\"\n",
    "    Validate that a matrix represents valid probabilities.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    P : jnp.ndarray\n",
    "        Probability matrix to validate\n",
    "    name : str\n",
    "        Name for debugging messages\n",
    "    axis : int or None\n",
    "        Axis along which probabilities should sum to 1\n",
    "    tolerance : float\n",
    "        Tolerance for sum check\n",
    "    \"\"\"\n",
    "    issues = []\n",
    "    \n",
    "    # Check for NaN/Inf\n",
    "    if check_nan_inf(P, name):\n",
    "        issues.append(f\"{name} contains NaN or Inf values\")\n",
    "    \n",
    "    # Check for negative values\n",
    "    if jnp.any(P < 0):\n",
    "        min_val = jnp.min(P)\n",
    "        issues.append(f\"{name} contains negative values (min: {min_val})\")\n",
    "    \n",
    "    # Check for values > 1\n",
    "    if jnp.any(P > 1 + tolerance):\n",
    "        max_val = jnp.max(P)\n",
    "        issues.append(f\"{name} contains values > 1 (max: {max_val})\")\n",
    "    \n",
    "    # Check sum constraint if axis specified\n",
    "    if axis is not None:\n",
    "        sums = jnp.sum(P, axis=axis)\n",
    "        if not jnp.allclose(sums, 1.0, atol=tolerance):\n",
    "            min_sum = jnp.min(sums)\n",
    "            max_sum = jnp.max(sums)\n",
    "            issues.append(f\"{name} sums along axis {axis} not equal to 1 (range: [{min_sum}, {max_sum}])\")\n",
    "    \n",
    "    if issues:\n",
    "        print(f\"Validation issues for {name}:\")\n",
    "        for issue in issues:\n",
    "            print(f\"  - {issue}\")\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "def debug_calculate_mutual_information(E_i, D_j, P_m=None):\n",
    "    \"\"\"\n",
    "    Debug version of mutual information calculation with checks.\n",
    "    \"\"\"\n",
    "    print(\"\\n=== Debug Mutual Information Calculation ===\")\n",
    "    \n",
    "    # Validate inputs\n",
    "    print(\"Checking inputs...\")\n",
    "    validate_probability_matrix(E_i, \"Encoder E_i\", axis=0)\n",
    "    validate_probability_matrix(D_j, \"Decoder D_j\", axis=0)\n",
    "    \n",
    "    num_symbols, num_messages = E_i.shape\n",
    "    \n",
    "    if P_m is None:\n",
    "        P_m = jnp.ones(num_messages) / num_messages\n",
    "    else:\n",
    "        validate_probability_matrix(P_m.reshape(1, -1), \"Prior P_m\", axis=1)\n",
    "    \n",
    "    # Compute composite channel matrix\n",
    "    C_ij = D_j @ E_i\n",
    "    print(f\"\\nComposite channel C_ij shape: {C_ij.shape}\")\n",
    "    validate_probability_matrix(C_ij, \"Composite channel C_ij\", axis=0)\n",
    "    \n",
    "    # Compute joint probability\n",
    "    P_joint = C_ij * P_m[jnp.newaxis, :]\n",
    "    print(f\"Joint probability P_joint shape: {P_joint.shape}\")\n",
    "    print(f\"P_joint sum: {jnp.sum(P_joint)} (should be 1.0)\")\n",
    "    \n",
    "    # Check for zeros that might cause log issues\n",
    "    num_zeros = jnp.sum(P_joint == 0)\n",
    "    print(f\"Number of exact zeros in P_joint: {num_zeros}\")\n",
    "    if num_zeros > 0:\n",
    "        print(\"  Warning: Zeros in joint probability may cause numerical issues\")\n",
    "    \n",
    "    # Compute marginals\n",
    "    P_m_prime = jnp.sum(P_joint, axis=1)\n",
    "    print(f\"\\nMarginal P(m') range: [{jnp.min(P_m_prime)}, {jnp.max(P_m_prime)}]\")\n",
    "    \n",
    "    # Check marginal product\n",
    "    P_marginal_product = jnp.outer(P_m_prime, P_m)\n",
    "    print(f\"Marginal product range: [{jnp.min(P_marginal_product)}, {jnp.max(P_marginal_product)}]\")\n",
    "    \n",
    "    # Check for potential division issues\n",
    "    zero_marginal_product = jnp.sum(P_marginal_product == 0)\n",
    "    print(f\"Zeros in marginal product: {zero_marginal_product}\")\n",
    "    \n",
    "    # Compute MI with detailed checks\n",
    "    epsilon = 1e-10\n",
    "    log_ratio = P_joint / (P_marginal_product + epsilon)\n",
    "    \n",
    "    print(f\"\\nLog ratio range: [{jnp.min(log_ratio)}, {jnp.max(log_ratio)}]\")\n",
    "    check_nan_inf(log_ratio, \"log_ratio\")\n",
    "    \n",
    "    # Use safe log computation\n",
    "    mutual_info = jnp.sum(jax.scipy.special.xlogy(P_joint, log_ratio))\n",
    "    \n",
    "    print(f\"\\nMutual information: {mutual_info}\")\n",
    "    check_nan_inf(mutual_info, \"mutual_info\")\n",
    "    \n",
    "    # Normalize\n",
    "    H_M = -jnp.sum(jax.scipy.special.xlogy(P_m, P_m))\n",
    "    print(f\"Entropy H(M): {H_M}\")\n",
    "    \n",
    "    return mutual_info\n",
    "\n",
    "def safe_normalize_decoder(D, epsilon=1e-10):\n",
    "    \"\"\"\n",
    "    Safely normalize decoder matrix with small epsilon to prevent division by zero.\n",
    "    \"\"\"\n",
    "    col_sums = jnp.sum(D, axis=0, keepdims=True)\n",
    "    \n",
    "    # Check for zero columns\n",
    "    zero_cols = jnp.sum(col_sums == 0)\n",
    "    if zero_cols > 0:\n",
    "        warnings.warn(f\"Decoder has {zero_cols} columns that sum to zero!\")\n",
    "    \n",
    "    # Add epsilon to prevent division by zero\n",
    "    D_normalized = D / (col_sums + epsilon)\n",
    "    \n",
    "    # Renormalize to ensure exact sum to 1\n",
    "    D_normalized = D_normalized / jnp.sum(D_normalized, axis=0, keepdims=True)\n",
    "    \n",
    "    return D_normalized\n",
    "\n",
    "def safe_gen_optimal_encoder(D, epsilon=1e-10):\n",
    "    \"\"\"\n",
    "    Generate optimal encoder with numerical safety checks.\n",
    "    \"\"\"\n",
    "    M, S = D.shape\n",
    "    \n",
    "    # Validate decoder\n",
    "    if not validate_probability_matrix(D, \"Decoder in gen_optimal_encoder\", axis=0):\n",
    "        print(\"Warning: Invalid decoder matrix!\")\n",
    "    \n",
    "    # Compute marginal P(s) under uniform P(m)\n",
    "    P_m = 1.0 / M\n",
    "    P_s = jnp.sum(D * P_m, axis=0)\n",
    "    \n",
    "    # Check for zero probabilities\n",
    "    zero_probs = jnp.sum(P_s == 0)\n",
    "    if zero_probs > 0:\n",
    "        warnings.warn(f\"P(s) has {zero_probs} zero entries!\")\n",
    "    \n",
    "    # Compute encoder with safety\n",
    "    numerator = D.T * P_s[:, jnp.newaxis]\n",
    "    denominator = jnp.sum(D * P_s[jnp.newaxis, :], axis=1) + epsilon\n",
    "    \n",
    "    # Check for potential issues\n",
    "    if jnp.any(denominator == epsilon):\n",
    "        warnings.warn(\"Some denominators in encoder computation are effectively zero!\")\n",
    "    \n",
    "    E = numerator / denominator[jnp.newaxis, :]\n",
    "    \n",
    "    # Validate output\n",
    "    validate_probability_matrix(E, \"Generated encoder\", axis=0)\n",
    "    \n",
    "    return E\n",
    "\n",
    "def debug_update(D, E_arr, learning_rate=0.01, v=None):\n",
    "    \"\"\"\n",
    "    Debug version of update function with extensive checking.\n",
    "    \"\"\"\n",
    "    print(\"\\n=== Debug Update Function ===\")\n",
    "    \n",
    "    # Check initial decoder\n",
    "    print(\"Initial decoder check:\")\n",
    "    validate_probability_matrix(D, \"Initial D\", axis=0)\n",
    "    \n",
    "    # Check encoders\n",
    "    for i, E in enumerate(E_arr):\n",
    "        validate_probability_matrix(E, f\"Encoder {i}\", axis=0)\n",
    "    \n",
    "    # Compute gradient with checks\n",
    "    grad_D = info_grad(D, E_arr, v)\n",
    "    print(f\"\\nGradient stats:\")\n",
    "    print(f\"  Shape: {grad_D.shape}\")\n",
    "    print(f\"  Range: [{jnp.min(grad_D)}, {jnp.max(grad_D)}]\")\n",
    "    print(f\"  Norm: {jnp.linalg.norm(grad_D)}\")\n",
    "    check_nan_inf(grad_D, \"Gradient\")\n",
    "    \n",
    "    # Check if gradient is too large\n",
    "    if jnp.linalg.norm(grad_D) > 100:\n",
    "        warnings.warn(f\"Large gradient norm: {jnp.linalg.norm(grad_D)}\")\n",
    "    \n",
    "    # Update step\n",
    "    D_new = D + learning_rate * grad_D\n",
    "    print(f\"\\nAfter gradient step:\")\n",
    "    print(f\"  D_new range: [{jnp.min(D_new)}, {jnp.max(D_new)}]\")\n",
    "    \n",
    "    # Check for negative values before normalization\n",
    "    if jnp.any(D_new < 0):\n",
    "        neg_count = jnp.sum(D_new < 0)\n",
    "        warnings.warn(f\"D_new has {neg_count} negative values before normalization!\")\n",
    "    \n",
    "    # Normalize\n",
    "    D_normalized = safe_normalize_decoder(D_new)\n",
    "    \n",
    "    print(\"\\nAfter normalization:\")\n",
    "    validate_probability_matrix(D_normalized, \"Normalized D\", axis=0)\n",
    "    \n",
    "    return D_normalized\n",
    "\n",
    "def add_nan_checking(func):\n",
    "    \"\"\"Decorator to add NaN checking to functions.\"\"\"\n",
    "    @wraps(func)\n",
    "    def wrapper(*args, **kwargs):\n",
    "        # Check inputs\n",
    "        for i, arg in enumerate(args):\n",
    "            if isinstance(arg, jnp.ndarray):\n",
    "                if check_nan_inf(arg, f\"Input arg {i} to {func.__name__}\"):\n",
    "                    print(f\"NaN/Inf detected in input to {func.__name__}!\")\n",
    "        \n",
    "        # Run function\n",
    "        result = func(*args, **kwargs)\n",
    "        \n",
    "        # Check output\n",
    "        if isinstance(result, jnp.ndarray):\n",
    "            if check_nan_inf(result, f\"Output of {func.__name__}\"):\n",
    "                print(f\"NaN/Inf detected in output of {func.__name__}!\")\n",
    "        elif isinstance(result, (list, tuple)):\n",
    "            for i, res in enumerate(result):\n",
    "                if isinstance(res, jnp.ndarray):\n",
    "                    if check_nan_inf(res, f\"Output {i} of {func.__name__}\"):\n",
    "                        print(f\"NaN/Inf detected in output {i} of {func.__name__}!\")\n",
    "        \n",
    "        return result\n",
    "    return wrapper\n",
    "\n",
    "def diagnose_convergence_step(decoders, encoders, iteration, learning_rate=0.01):\n",
    "    \"\"\"\n",
    "    Detailed diagnosis of a single convergence step.\n",
    "    \"\"\"\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"DIAGNOSING ITERATION {iteration}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    N = len(decoders)\n",
    "    \n",
    "    # Check all current decoders and encoders\n",
    "    for i in range(N):\n",
    "        print(f\"\\nAgent {i}:\")\n",
    "        valid_d = validate_probability_matrix(decoders[i], f\"Decoder {i}\", axis=0)\n",
    "        valid_e = validate_probability_matrix(encoders[i], f\"Encoder {i}\", axis=0) \n",
    "        \n",
    "        if not valid_d or not valid_e:\n",
    "            print(f\"  WARNING: Agent {i} has invalid matrices!\")\n",
    "    \n",
    "    # Compute mutual information matrix\n",
    "    mi_matrix = jnp.zeros((N, N))\n",
    "    for i in range(N):\n",
    "        for j in range(N):\n",
    "            if i != j:\n",
    "                try:\n",
    "                    mi = calculate_mutual_information_jax(encoders[j], decoders[i])\n",
    "                    mi_matrix = mi_matrix.at[i, j].set(mi)\n",
    "                    \n",
    "                    if jnp.isnan(mi) or jnp.isinf(mi):\n",
    "                        print(f\"\\nNaN/Inf detected in MI({i},{j})!\")\n",
    "                        print(f\"Running detailed debug...\")\n",
    "                        debug_calculate_mutual_information(encoders[j], decoders[i])\n",
    "                except Exception as e:\n",
    "                    print(f\"\\nError computing MI({i},{j}): {e}\")\n",
    "    \n",
    "    print(f\"\\nMutual Information Matrix:\")\n",
    "    print(f\"  Contains NaN: {jnp.any(jnp.isnan(mi_matrix))}\")\n",
    "    print(f\"  Contains Inf: {jnp.any(jnp.isinf(mi_matrix))}\")\n",
    "    print(f\"  Range: [{jnp.min(mi_matrix[mi_matrix > 0])}, {jnp.max(mi_matrix)}]\")\n",
    "    \n",
    "    # Test one update step\n",
    "    print(f\"\\nTesting update for agent 0...\")\n",
    "    other_encoders = [encoders[j] for j in range(N) if j != 0]\n",
    "    D_new = debug_update(decoders[0], other_encoders, learning_rate)\n",
    "    \n",
    "    return mi_matrix\n",
    "\n",
    "def gen_D_binary(S, M, key=None):\n",
    "    \"\"\"Generate a decoder matrix D where D[m,s] = P(m|s)\"\"\"\n",
    "    if key is None:\n",
    "        key = jax.random.PRNGKey(0)\n",
    "    \n",
    "    D = jnp.zeros((M, S))\n",
    "    for col in range(S):\n",
    "        subkey1, subkey2, key = jax.random.split(key, 3)\n",
    "        # For each symbol, randomly assign probabilities to messages\n",
    "        num_messages = jax.random.randint(subkey1, (), 1, M+1)\n",
    "        selected_messages = jax.random.choice(subkey2, M, shape=(M,), replace=True)\n",
    "        unique_messages = jnp.unique(selected_messages[:num_messages])\n",
    "        D = D.at[unique_messages, col].set(1.0 / len(unique_messages))\n",
    "    return D\n",
    "\n",
    "def gen_optimal_encoder(D):\n",
    "    \"\"\"\n",
    "    Generate the optimal encoder E given decoder D.\n",
    "    D: (M, S) matrix where D[m,s] = P(m|s)\n",
    "    Returns E: (S, M) matrix where E[s,m] = P(s|m)\n",
    "    \"\"\"\n",
    "    M, S = D.shape\n",
    "    \n",
    "    # Compute marginal P(s) under uniform P(m) = 1/M\n",
    "    P_m = 1.0 / M\n",
    "    P_s = jnp.sum(D * P_m, axis=0)  # P(s) = sum_m P(m|s)P(m)\n",
    "    \n",
    "    # Compute encoder using Bayes rule\n",
    "    # E(s|m) = D(m|s)P(s) / sum_s' D(m|s')P(s')\n",
    "    # Vectorized computation\n",
    "    numerator = D.T * P_s[:, jnp.newaxis]  # (S, M)\n",
    "    denominator = jnp.sum(D * P_s[jnp.newaxis, :], axis=1)  # (M,)\n",
    "    E = numerator / (denominator[jnp.newaxis, :])\n",
    "    \n",
    "    return E\n",
    "\n",
    "@jit\n",
    "def calculate_mutual_information_jax(E_i, D_j, P_m=None):\n",
    "    \"\"\"\n",
    "    JAX-compatible calculation of normalized mutual information.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    E_i : jnp.ndarray\n",
    "        Encoder matrix for agent i, shape (|S|, |M|) where E_i[s,m] = P(s|m)\n",
    "    D_j : jnp.ndarray  \n",
    "        Decoder matrix for agent j, shape (|M|, |S|) where D_j[m',s] = P(m'|s)\n",
    "    P_m : jnp.ndarray, optional\n",
    "        Prior distribution over messages, shape (|M|,). If None, assumes uniform.\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    I_ij_normalized : float\n",
    "        Normalized mutual information I(M_i; M_j')/H(M), in range [0,1]\n",
    "    \"\"\"\n",
    "    \n",
    "    # Get dimensions\n",
    "    num_symbols, num_messages = E_i.shape\n",
    "    \n",
    "    # Set uniform prior if not provided\n",
    "    if P_m is None:\n",
    "        P_m = jnp.ones(num_messages) / num_messages\n",
    "    \n",
    "    # Compute composite channel matrix C_ij\n",
    "    C_ij = D_j @ E_i\n",
    "    \n",
    "    # Compute joint probability matrix\n",
    "    P_joint = C_ij * P_m[jnp.newaxis, :]\n",
    "    \n",
    "    # Compute marginal P(m')\n",
    "    P_m_prime = jnp.sum(P_joint, axis=1)\n",
    "    \n",
    "    # Compute mutual information using vectorized operations\n",
    "    epsilon = 1e-10\n",
    "    # Create outer product of marginals\n",
    "    P_marginal_product = jnp.outer(P_m_prime, P_m)\n",
    "\n",
    "    # TODO: is this logic actually robust to p=0?\n",
    "    # Compute MI with numerical stability\n",
    "    # Using xlogy for x * log(y) which handles x=0 case properly\n",
    "    log_ratio = P_joint / (P_marginal_product + epsilon)\n",
    "    mutual_info = jnp.sum(jax.scipy.special.xlogy(P_joint, log_ratio))\n",
    "    \n",
    "    # Normalize by entropy of M\n",
    "    # H_M = jnp.sum(P_m * jnp.log(P_m))\n",
    "    # I_ij_normalized = mutual_info / H_M\n",
    "    \n",
    "    return mutual_info\n",
    "\n",
    "def mutual_info_sum(D, E_arr, v=None):\n",
    "    \"\"\"\n",
    "    Calculate weighted sum of mutual information for decoder D with multiple encoders.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    D : jnp.ndarray\n",
    "        Decoder matrix, shape (|M|, |S|)\n",
    "    E_arr : list of jnp.ndarray\n",
    "        List of encoder matrices, each shape (|S|, |M|)\n",
    "    v : jnp.ndarray, optional\n",
    "        Weights for each encoder, default is uniform\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    weighted_sum : float\n",
    "        Weighted sum of mutual information values\n",
    "    \"\"\"\n",
    "    n = len(E_arr)\n",
    "    if v is None:\n",
    "        v = jnp.ones(n) / n\n",
    "    \n",
    "    # Stack encoders for vectorized computation\n",
    "    E_stack = jnp.stack(E_arr, axis=0)  # (n, |S|, |M|)\n",
    "    \n",
    "    # Vectorized mutual information calculation\n",
    "    vmap_mi = vmap(lambda E: calculate_mutual_information_jax(E, D))\n",
    "    mi_values = vmap_mi(E_stack)\n",
    "    \n",
    "    return jnp.sum(v * mi_values)\n",
    "\n",
    "def info_grad(D, E_arr, v=None):\n",
    "    \"\"\"\n",
    "    Compute gradient of mutual information sum with respect to decoder D.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    D : jnp.ndarray  \n",
    "        Decoder matrix for agent j, shape (|M|, |S|) where D_j[m',s] = P(m'|s)\n",
    "    E_arr : list[jnp.ndarray] of length n\n",
    "        List of encoder matrices for agent i, shape (|S|, |M|) where E_i[s,m] = P(s|m)\n",
    "    v : jnp.ndarray\n",
    "        A n-vector of weights to prioritize the mutual information from different channels\n",
    "        default = uniform weights\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    grad_D: jnp.ndarray\n",
    "        The gradient of the weighted mutual information sum with respect to D\n",
    "    \"\"\"\n",
    "    # Create gradient function\n",
    "    grad_fn = grad(mutual_info_sum, argnums=0)\n",
    "    \n",
    "    # Compute gradient\n",
    "    grad_D = grad_fn(D, E_arr, v)\n",
    "    \n",
    "    return grad_D\n",
    "\n",
    "def normalize_decoder(D):\n",
    "    \"\"\"\n",
    "    Normalize decoder matrix so columns sum to 1.\n",
    "    \"\"\"\n",
    "    return (D + 1e-10) / (jnp.sum(D + 1e-10, axis=0, keepdims=True))\n",
    "\n",
    "def update(D, E_arr, learning_rate=0.01, v=None):\n",
    "    \"\"\"\n",
    "    Update decoder D to maximize weighted mutual information from encoders E_arr.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    D : jnp.ndarray\n",
    "        Current decoder matrix\n",
    "    E_arr : list[jnp.ndarray]\n",
    "        List of encoder matrices to receive from\n",
    "    learning_rate : float\n",
    "        Step size for gradient ascent\n",
    "    v : jnp.ndarray, optional\n",
    "        Weights for each encoder\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    D_new : jnp.ndarray\n",
    "        Updated and normalized decoder matrix\n",
    "    \"\"\"\n",
    "    # Compute gradient\n",
    "    grad_D = info_grad(D, E_arr, v)\n",
    "    \n",
    "    # Gradient ascent step\n",
    "    D_new = D + learning_rate * grad_D\n",
    "\n",
    "    # Set any negative values to 0\n",
    "    D_new = jnp.maximum(D_new, 0.0)\n",
    "    \n",
    "    # Project back to probability simplex by normalization\n",
    "    D_new = normalize_decoder(D_new)\n",
    "    \n",
    "    return D_new\n",
    "\n",
    "# Additional utilities for the full system\n",
    "\n",
    "def initialize_agents(N, S, M, key=None):\n",
    "    \"\"\"\n",
    "    Initialize N agents with random decoders and optimal encoders.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    N : int\n",
    "        Number of agents\n",
    "    S : int\n",
    "        Size of shared symbol space\n",
    "    M : int\n",
    "        Size of message space\n",
    "    key : jax.random.PRNGKey\n",
    "        Random key for initialization\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    decoders : list of jnp.ndarray\n",
    "        List of decoder matrices\n",
    "    encoders : list of jnp.ndarray\n",
    "        List of optimal encoder matrices\n",
    "    \"\"\"\n",
    "    if key is None:\n",
    "        key = jax.random.PRNGKey(0)\n",
    "    \n",
    "    decoders = []\n",
    "    encoders = []\n",
    "    \n",
    "    for i in range(N):\n",
    "        key, subkey = jax.random.split(key)\n",
    "        # Initialize random decoder\n",
    "        D = jax.random.uniform(subkey, (M, S))\n",
    "        D = normalize_decoder(D)\n",
    "        decoders.append(D)\n",
    "        \n",
    "        # Compute optimal encoder\n",
    "        E = gen_optimal_encoder(D)\n",
    "        encoders.append(E)\n",
    "    \n",
    "    return decoders, encoders\n",
    "\n",
    "def simulate_convergence(N, S, M, num_iterations=100, learning_rate=0.01, key=None, home_planet=False):\n",
    "    \"\"\"\n",
    "    Simulate the convergence of the multi-agent language system.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    N : int\n",
    "        Number of agents\n",
    "    S : int\n",
    "        Size of shared symbol space\n",
    "    M : int\n",
    "        Size of message space\n",
    "    num_iterations : int\n",
    "        Number of update iterations\n",
    "    learning_rate : float\n",
    "        Learning rate for decoder updates\n",
    "    key : jax.random.PRNGKey\n",
    "        Random key for initialization\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    history : dict\n",
    "        Dictionary containing evolution history\n",
    "    \"\"\"\n",
    "    # Initialize agents\n",
    "    decoders, encoders = initialize_agents(N, S, M, key)\n",
    "    \n",
    "    # Track history\n",
    "    history = {\n",
    "        'mutual_info': [],\n",
    "        'decoders': [decoders],\n",
    "        'encoders': [encoders]\n",
    "    }\n",
    "    \n",
    "    for iteration in tqdm(range(num_iterations)):\n",
    "        # Update each agent's decoder\n",
    "        new_decoders = []\n",
    "        new_encoders = []\n",
    "        \n",
    "        for i in range(N):\n",
    "            # Get encoders from all other agents\n",
    "            other_encoders = [encoders[j] for j in range(N) if j != i]\n",
    "\n",
    "            if home_planet:\n",
    "                other_encoders.append(history['encoders'][0][i]) # Also optimize for mutual info with original language\n",
    "            \n",
    "            # Update decoder\n",
    "            D_new = update(decoders[i], other_encoders, learning_rate)\n",
    "            new_decoders.append(D_new)\n",
    "            \n",
    "            # Compute new optimal encoder\n",
    "            E_new = gen_optimal_encoder(D_new)\n",
    "            new_encoders.append(E_new)\n",
    "        \n",
    "        decoders = new_decoders\n",
    "        encoders = new_encoders\n",
    "        \n",
    "        # Record mutual information matrix\n",
    "        mi_matrix = jnp.zeros((N, N))\n",
    "        for i in range(N):\n",
    "            for j in range(N):\n",
    "                if i != j:\n",
    "                    mi_matrix = mi_matrix.at[i, j].set(\n",
    "                        calculate_mutual_information_jax(encoders[j], decoders[i])\n",
    "                    )\n",
    "        \n",
    "        history['mutual_info'].append(mi_matrix)\n",
    "        history['decoders'].append(decoders)\n",
    "        history['encoders'].append(encoders)\n",
    "    \n",
    "    return history\n",
    "\n",
    "def simulate_convergence_debug(N, S, M, num_iterations=100, learning_rate=0.01, \n",
    "                              key=None, home_planet=False, debug_frequency=10):\n",
    "    \"\"\"\n",
    "    Debug version of simulate_convergence with extensive checking.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    debug_frequency : int\n",
    "        How often to print detailed debug info (every N iterations)\n",
    "    \"\"\"\n",
    "    print(f\"Starting simulation with N={N}, S={S}, M={M}\")\n",
    "    print(f\"Learning rate: {learning_rate}\")\n",
    "    \n",
    "    # Initialize agents with safety checks\n",
    "    decoders, encoders = initialize_agents(N, S, M, key)\n",
    "    \n",
    "    # Validate initialization\n",
    "    print(\"\\nValidating initial conditions...\")\n",
    "    all_valid = True\n",
    "    for i in range(N):\n",
    "        if not validate_probability_matrix(decoders[i], f\"Initial decoder {i}\", axis=0):\n",
    "            all_valid = False\n",
    "        if not validate_probability_matrix(encoders[i], f\"Initial encoder {i}\", axis=0):\n",
    "            all_valid = False\n",
    "    \n",
    "    if not all_valid:\n",
    "        warnings.warn(\"Initial conditions have validation issues!\")\n",
    "    \n",
    "    # Track history\n",
    "    history = {\n",
    "        'mutual_info': [],\n",
    "        'decoders': [decoders],\n",
    "        'encoders': [encoders],\n",
    "        'nan_iterations': [],  # Track where NaNs appear\n",
    "        'gradient_norms': []   # Track gradient magnitudes\n",
    "    }\n",
    "    \n",
    "    # Track when issues first appear\n",
    "    first_nan_iteration = None\n",
    "    \n",
    "    for iteration in tqdm(range(num_iterations)):\n",
    "        # Detailed debug every N iterations or when NaN detected\n",
    "        do_detailed_debug = (iteration % debug_frequency == 0) or (first_nan_iteration is not None)\n",
    "        \n",
    "        if do_detailed_debug:\n",
    "            print(f\"\\n{'='*60}\")\n",
    "            print(f\"Iteration {iteration}\")\n",
    "            print(f\"{'='*60}\")\n",
    "        \n",
    "        # Update each agent's decoder\n",
    "        new_decoders = []\n",
    "        new_encoders = []\n",
    "        gradient_norms = []\n",
    "        \n",
    "        for i in range(N):\n",
    "            # Get encoders from all other agents\n",
    "            other_encoders = [encoders[j] for j in range(N) if j != i]\n",
    "            \n",
    "            if home_planet:\n",
    "                other_encoders.append(history['encoders'][0][i])\n",
    "            \n",
    "            # Check current decoder before update\n",
    "            if check_nan_inf(decoders[i], f\"Decoder {i} before update\"):\n",
    "                print(f\"  NaN detected in decoder {i} at iteration {iteration}\")\n",
    "                if first_nan_iteration is None:\n",
    "                    first_nan_iteration = iteration\n",
    "            \n",
    "            # Compute gradient for monitoring\n",
    "            grad_D = info_grad(decoders[i], other_encoders)\n",
    "            grad_norm = jnp.linalg.norm(grad_D)\n",
    "            gradient_norms.append(grad_norm)\n",
    "            \n",
    "            if do_detailed_debug:\n",
    "                print(f\"\\nAgent {i} gradient norm: {grad_norm:.4f}\")\n",
    "            \n",
    "            # Check for exploding gradients\n",
    "            if grad_norm > 100:\n",
    "                warnings.warn(f\"Large gradient norm {grad_norm} for agent {i} at iteration {iteration}\")\n",
    "            \n",
    "            # Update decoder with safety\n",
    "            try:\n",
    "                if do_detailed_debug and i == 0:  # Detailed debug for first agent\n",
    "                    D_new = debug_update(decoders[i], other_encoders, learning_rate)\n",
    "                else:\n",
    "                    D_new = update(decoders[i], other_encoders, learning_rate)\n",
    "                \n",
    "                # Extra safety: clip extreme values\n",
    "                D_new = jnp.clip(D_new, 1e-10, 1.0)\n",
    "                D_new = safe_normalize_decoder(D_new)\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"Error updating agent {i} at iteration {iteration}: {e}\")\n",
    "                D_new = decoders[i]  # Keep old decoder if update fails\n",
    "            \n",
    "            new_decoders.append(D_new)\n",
    "            \n",
    "            # Compute new optimal encoder with safety\n",
    "            try:\n",
    "                E_new = safe_gen_optimal_encoder(D_new)\n",
    "            except Exception as e:\n",
    "                print(f\"Error generating encoder for agent {i} at iteration {iteration}: {e}\")\n",
    "                E_new = encoders[i]  # Keep old encoder if generation fails\n",
    "            \n",
    "            new_encoders.append(E_new)\n",
    "        \n",
    "        decoders = new_decoders\n",
    "        encoders = new_encoders\n",
    "        history['gradient_norms'].append(gradient_norms)\n",
    "        \n",
    "        # Record mutual information matrix with checks\n",
    "        mi_matrix = jnp.zeros((N, N))\n",
    "        nan_found = False\n",
    "        \n",
    "        for i in range(N):\n",
    "            for j in range(N):\n",
    "                if i != j:\n",
    "                    try:\n",
    "                        mi = calculate_mutual_information_jax(encoders[j], decoders[i])\n",
    "                        \n",
    "                        if jnp.isnan(mi) or jnp.isinf(mi):\n",
    "                            nan_found = True\n",
    "                            print(f\"\\nNaN/Inf in MI({i},{j}) at iteration {iteration}!\")\n",
    "                            if first_nan_iteration is None:\n",
    "                                first_nan_iteration = iteration\n",
    "                                # Run detailed debug\n",
    "                                debug_calculate_mutual_information(encoders[j], decoders[i])\n",
    "                        else:\n",
    "                            mi_matrix = mi_matrix.at[i, j].set(mi)\n",
    "                            \n",
    "                    except Exception as e:\n",
    "                        print(f\"Error computing MI({i},{j}) at iteration {iteration}: {e}\")\n",
    "                        nan_found = True\n",
    "        \n",
    "        if nan_found:\n",
    "            history['nan_iterations'].append(iteration)\n",
    "        \n",
    "        history['mutual_info'].append(mi_matrix)\n",
    "        history['decoders'].append(decoders)\n",
    "        history['encoders'].append(encoders)\n",
    "        \n",
    "        # Summary statistics every debug_frequency iterations\n",
    "        if do_detailed_debug:\n",
    "            avg_mi = jnp.mean(mi_matrix[mi_matrix > 0]) if jnp.any(mi_matrix > 0) else 0\n",
    "            max_grad = jnp.max(jnp.array(gradient_norms))\n",
    "            print(f\"\\nIteration {iteration} summary:\")\n",
    "            print(f\"  Average MI: {avg_mi:.4f}\")\n",
    "            print(f\"  Max gradient norm: {max_grad:.4f}\")\n",
    "            print(f\"  NaN detected: {nan_found}\")\n",
    "        \n",
    "        # Early stopping if too many NaNs\n",
    "        if len(history['nan_iterations']) > 5:\n",
    "            print(f\"\\nStopping early due to persistent NaN values\")\n",
    "            break\n",
    "    \n",
    "    # Final diagnostic report\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(\"SIMULATION COMPLETE - DIAGNOSTIC REPORT\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    if history['nan_iterations']:\n",
    "        print(f\"NaN values detected in iterations: {history['nan_iterations']}\")\n",
    "        print(f\"First NaN at iteration: {first_nan_iteration}\")\n",
    "    else:\n",
    "        print(\"No NaN values detected!\")\n",
    "    \n",
    "    # Analyze gradient behavior\n",
    "    all_grad_norms = jnp.array([jnp.max(jnp.array(g)) for g in history['gradient_norms']])\n",
    "    print(f\"\\nGradient norm statistics:\")\n",
    "    print(f\"  Mean max gradient: {jnp.mean(all_grad_norms):.4f}\")\n",
    "    print(f\"  Max gradient ever: {jnp.max(all_grad_norms):.4f}\")\n",
    "    \n",
    "    # Check final state\n",
    "    print(f\"\\nFinal state check:\")\n",
    "    final_mi = history['mutual_info'][-1] if history['mutual_info'] else None\n",
    "    if final_mi is not None:\n",
    "        valid_mi = jnp.sum(~jnp.isnan(final_mi) & (final_mi > 0))\n",
    "        print(f\"  Valid MI entries: {valid_mi}/{N*(N-1)}\")\n",
    "        if valid_mi > 0:\n",
    "            print(f\"  Average final MI: {jnp.mean(final_mi[~jnp.isnan(final_mi) & (final_mi > 0)]):.4f}\")\n",
    "    \n",
    "    return history\n",
    "\n",
    "# Additional diagnostic function to analyze where things go wrong\n",
    "def analyze_nan_source(history):\n",
    "    \"\"\"\n",
    "    Analyze history to determine likely source of NaN values.\n",
    "    \"\"\"\n",
    "    print(\"\\n=== NaN Source Analysis ===\")\n",
    "    \n",
    "    if not history['nan_iterations']:\n",
    "        print(\"No NaN iterations to analyze\")\n",
    "        return\n",
    "    \n",
    "    first_nan_iter = history['nan_iterations'][0]\n",
    "    print(f\"First NaN at iteration: {first_nan_iter}\")\n",
    "    \n",
    "    # Check gradient behavior before NaN\n",
    "    if first_nan_iter > 0:\n",
    "        grad_norms_before = history['gradient_norms'][first_nan_iter-1]\n",
    "        print(f\"\\nGradient norms before first NaN:\")\n",
    "        for i, norm in enumerate(grad_norms_before):\n",
    "            print(f\"  Agent {i}: {norm:.4f}\")\n",
    "    \n",
    "    # Check decoders at NaN iteration\n",
    "    print(f\"\\nChecking decoders at iteration {first_nan_iter}:\")\n",
    "    for i, decoder in enumerate(history['decoders'][first_nan_iter]):\n",
    "        col_sums = jnp.sum(decoder, axis=0)\n",
    "        min_sum = jnp.min(col_sums)\n",
    "        max_sum = jnp.max(col_sums)\n",
    "        zero_cols = jnp.sum(col_sums < 1e-10)\n",
    "        print(f\"  Decoder {i}: col_sum range [{min_sum:.6f}, {max_sum:.6f}], zero cols: {zero_cols}\")\n",
    "    \n",
    "    # Check for specific patterns\n",
    "    print(\"\\nPossible causes:\")\n",
    "    \n",
    "    # Check if gradients exploded\n",
    "    all_grad_norms = jnp.array([jnp.max(jnp.array(g)) for g in history['gradient_norms'][:first_nan_iter]])\n",
    "    if len(all_grad_norms) > 0 and jnp.max(all_grad_norms) > 50:\n",
    "        print(\"  - Gradient explosion detected (max norm > 50)\")\n",
    "        print(f\"    Suggestion: Reduce learning rate (current might be too high)\")\n",
    "    \n",
    "    # Check if decoders became degenerate\n",
    "    for i, decoder in enumerate(history['decoders'][first_nan_iter]):\n",
    "        if jnp.any(jnp.sum(decoder, axis=0) < 1e-10):\n",
    "            print(f\"  - Decoder {i} has near-zero columns (degenerate)\")\n",
    "            print(f\"    Suggestion: Add regularization or use safe_normalize_decoder\")\n",
    "    \n",
    "    # Check if it's related to home planet constraint\n",
    "    if 'home_planet' in history and history.get('home_planet', False):\n",
    "        print(\"  - Home planet constraint is active\")\n",
    "        print(\"    This adds additional constraints that might cause instability\")\n",
    "\n",
    "# Example usage and testing\n",
    "# Set parameters\n",
    "N = 10 # Number of agents\n",
    "S = 3  # Symbol space size\n",
    "M = 3  # Message space size\n",
    "\n",
    "# Initialize\n",
    "key = jax.random.PRNGKey(42)\n",
    "decoders, encoders = initialize_agents(N, S, M, key)\n",
    "\n",
    "# Test gradient computation\n",
    "D_test = decoders[0]\n",
    "E_test = encoders[1:]\n",
    "\n",
    "# Compute gradient\n",
    "grad_D = info_grad(D_test, E_test)\n",
    "print(f\"Gradient shape: {grad_D.shape}\")\n",
    "print(f\"Gradient norm: {jnp.linalg.norm(grad_D):.4f}\")\n",
    "\n",
    "# Test update\n",
    "D_new = update(D_test, E_test, learning_rate=0.1)\n",
    "print(f\"Decoder still normalized: {jnp.allclose(jnp.sum(D_new, axis=0), 1.0)}\")\n",
    "\n",
    "# Run short simulation\n",
    "history = simulate_convergence(N, S, M, num_iterations=100, learning_rate=0.5, key=key, home_planet=True)\n",
    "\n",
    "print(f\"\\nInitial average mutual information: {jnp.mean(history['mutual_info'][0]):.4f}\")\n",
    "print(f\"Final average mutual information: {jnp.mean(history['mutual_info'][-1]):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "99afee02-7606-4dcd-9ae5-da1fa787bead",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x383587250>]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "mean_mutual_info = [jnp.mean(i) for i in history['mutual_info']]\n",
    "\n",
    "plt.plot(mean_mutual_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f1736435-19d3-4f68-9ace-2ee723bf4abb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "sns.heatmap(history['mutual_info'][0], vmax=0.016)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "725b7c05-c597-4683-af05-41002664f3b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.heatmap(history['mutual_info'][75], vmax=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "49f52fbb-4d7b-47fa-a280-6bfecb19d924",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def gen_D_binary(S, M):\n",
    "    \"\"\"Generate a decoder matrix D where D[m,s] = P(m|s)\"\"\"\n",
    "    D = np.zeros((M, S))\n",
    "    for col in range(S):\n",
    "        # For each symbol, randomly assign probabilities to messages\n",
    "        selected_messages = np.random.choice(np.arange(M), size=np.random.randint(1, M+1), replace=True)\n",
    "        unique_messages = np.unique(selected_messages)\n",
    "        D[unique_messages, col] = 1.0 / len(unique_messages)\n",
    "    return D\n",
    "\n",
    "def gen_optimal_encoder(D):\n",
    "    \"\"\"\n",
    "    Generate the optimal encoder E given decoder D.\n",
    "    D: (M, S) matrix where D[m,s] = P(m|s)\n",
    "    Returns E: (S, M) matrix where E[s,m] = P(s|m)\n",
    "    \"\"\"\n",
    "    M, S = D.shape\n",
    "    \n",
    "    # Compute marginal P(s) under uniform P(m) = 1/M\n",
    "    P_m = 1.0 / M\n",
    "    P_s = np.sum(D * P_m, axis=0)  # P(s) = sum_m P(m|s)P(m)\n",
    "    \n",
    "    # Compute encoder using Bayes rule\n",
    "    # E(s|m) = D(m|s)P(s) / sum_s' D(m|s')P(s')\n",
    "    E = np.zeros((S, M))\n",
    "    for m in range(M):\n",
    "        denominator = np.sum(D[m, :] * P_s)\n",
    "        if denominator > 0:\n",
    "            E[:, m] = D[m, :] * P_s / denominator\n",
    "    \n",
    "    return E\n",
    "\n",
    "def test_encoder_optimality(D, E, num_samples=10000):\n",
    "    \"\"\"\n",
    "    Test that the encoder E is optimal for decoder D by:\n",
    "    1. Verifying it maximizes mutual information I(M; M')\n",
    "    2. Checking that it minimizes reconstruction error\n",
    "    \"\"\"\n",
    "    M, S = D.shape\n",
    "    \n",
    "    # Test 1: Verify the encoder satisfies the Bayes optimal condition\n",
    "    P_m = 1.0 / M\n",
    "    P_s = np.sum(D * P_m, axis=0)\n",
    "    \n",
    "    for m in range(M):\n",
    "        denominator = np.sum(D[m, :] * P_s)\n",
    "        if denominator > 0:\n",
    "            expected_E = D[m, :] * P_s / denominator\n",
    "            assert np.allclose(E[:, m], expected_E), f\"Encoder doesn't match Bayes optimal for message {m}\"\n",
    "    \n",
    "    # Test 2: Empirical reconstruction - sample messages and check recovery\n",
    "    reconstruction_matrix = E.T @ D.T  # P(m'|m) = sum_s P(m'|s)P(s|m)\n",
    "    \n",
    "    # For optimal encoder, diagonal should be maximized\n",
    "    diagonal_sum = np.trace(reconstruction_matrix)\n",
    "    \n",
    "    # Compare with random encoder\n",
    "    random_E = np.random.rand(S, M)\n",
    "    random_E = random_E / random_E.sum(axis=0, keepdims=True)  # Normalize columns\n",
    "    random_reconstruction = random_E.T @ D.T\n",
    "    random_diagonal = np.trace(random_reconstruction)\n",
    "    \n",
    "    assert diagonal_sum >= random_diagonal - 1e-6, \"Optimal encoder should have better reconstruction than random\"\n",
    "    \n",
    "    # Test 3: Compute mutual information\n",
    "    # I(M;M') = sum_m,m' P(m,m') log(P(m,m') / (P(m)P(m')))\n",
    "    P_joint = np.zeros((M, M))\n",
    "    for m in range(M):\n",
    "        for m_prime in range(M):\n",
    "            P_joint[m, m_prime] = P_m * reconstruction_matrix[m, m_prime]\n",
    "    \n",
    "    P_m_prime = np.sum(P_joint, axis=0)\n",
    "    \n",
    "    MI = 0\n",
    "    for m in range(M):\n",
    "        for m_prime in range(M):\n",
    "            if P_joint[m, m_prime] > 0:\n",
    "                MI += P_joint[m, m_prime] * np.log(P_joint[m, m_prime] / (P_m * P_m_prime[m_prime]))\n",
    "    \n",
    "    print(f\"Mutual Information I(M;M'): {MI:.4f}\")\n",
    "    print(f\"Max possible MI (log M): {np.log(M):.4f}\")\n",
    "    print(f\"Reconstruction accuracy (trace): {diagonal_sum:.4f}\")\n",
    "    print(f\"Random encoder accuracy: {random_diagonal:.4f}\")\n",
    "    \n",
    "    return True\n",
    "\n",
    "def calculate_normalized_mutual_information(E_i, D_j, P_m=None, P_m_prime=None):\n",
    "    \"\"\"\n",
    "    Calculate normalized mutual information between agent i's messages and agent j's interpretations.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    E_i : np.ndarray\n",
    "        Encoder matrix for agent i, shape (|S|, |M|) where E_i[s,m] = P(s|m)\n",
    "    D_j : np.ndarray  \n",
    "        Decoder matrix for agent j, shape (|M|, |S|) where D_j[m',s] = P(m'|s)\n",
    "    P_m : np.ndarray, optional\n",
    "        Prior distribution over messages, shape (|M|,). If None, assumes uniform.\n",
    "    P_m_prime : np.ndarray, optional\n",
    "        Not used in calculation (marginal is derived). Included for interface consistency.\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    I_ij_normalized : float\n",
    "        Normalized mutual information I(M_i; M_j')/H(M), in range [0,1]\n",
    "    C_ij : np.ndarray\n",
    "        Composite channel matrix, shape (|M|, |M|) where C_ij[m',m] = P(m'|m; i->j)\n",
    "    \"\"\"\n",
    "    \n",
    "    # Get dimensions\n",
    "    num_symbols, num_messages = E_i.shape\n",
    "    assert D_j.shape == (num_messages, num_symbols), \"Decoder shape mismatch\"\n",
    "    \n",
    "    # Set uniform prior if not provided\n",
    "    if P_m is None:\n",
    "        P_m = np.ones(num_messages) / num_messages\n",
    "    \n",
    "    # Step 1: Compute composite channel matrix C_ij\n",
    "    # C_ij[m',m] = sum_s D_j[m',s] * E_i[s,m]\n",
    "    C_ij = D_j @ E_i  # Matrix multiplication gives us the sum over s\n",
    "    \n",
    "    # Step 2: Compute joint probability distribution\n",
    "    # P(m, m') = P(m) * P(m'|m; i->j)\n",
    "    # Create P_joint as outer product, then multiply by channel probabilities\n",
    "    P_joint = np.outer(P_m, np.ones(num_messages)) * C_ij.T\n",
    "    P_joint = P_joint.T  # Transpose to get P_joint[m',m]\n",
    "    \n",
    "    # Step 3: Compute marginal P(m')\n",
    "    P_m_prime_marginal = np.sum(P_joint, axis=1)  # Sum over m\n",
    "    \n",
    "    # Step 4: Compute mutual information\n",
    "    # I(M_i; M_j') = sum_{m,m'} P(m,m') log2(P(m,m')/(P(m)P(m')))\n",
    "    mutual_info = 0.0\n",
    "    epsilon = 1e-15  # Small constant to avoid log(0)\n",
    "    \n",
    "    for m in range(num_messages):\n",
    "        for m_prime in range(num_messages):\n",
    "            if P_joint[m_prime, m] > epsilon:\n",
    "                mutual_info += P_joint[m_prime, m] * np.log2(\n",
    "                    P_joint[m_prime, m] / (P_m[m] * P_m_prime_marginal[m_prime] + epsilon)\n",
    "                )\n",
    "    \n",
    "    # Step 5: Normalize by H(M) = log2(|M|) for uniform distribution\n",
    "    # For non-uniform P_m, use actual entropy\n",
    "    if np.allclose(P_m, 1/num_messages):\n",
    "        H_M = np.log2(num_messages)\n",
    "    else:\n",
    "        H_M = -np.sum(P_m * np.log2(P_m + epsilon))\n",
    "    \n",
    "    I_ij_normalized = mutual_info / H_M\n",
    "    \n",
    "    return I_ij_normalized, C_ij\n",
    "\n",
    "\n",
    "# Alternative implementation using matrix operations for efficiency\n",
    "def calculate_normalized_mutual_information_vectorized(E_i, D_j, P_m=None, P_m_prime=None):\n",
    "    \"\"\"\n",
    "    Vectorized version of normalized mutual information calculation.\n",
    "    \"\"\"\n",
    "    # Get dimensions\n",
    "    num_symbols, num_messages = E_i.shape\n",
    "    \n",
    "    # Set uniform prior if not provided\n",
    "    if P_m is None:\n",
    "        P_m = np.ones(num_messages) / num_messages\n",
    "    \n",
    "    # Compute composite channel matrix C_ij\n",
    "    C_ij = D_j @ E_i\n",
    "    \n",
    "    # Compute joint probability matrix: P_joint_{m', m} = probability(m' | m) x p(m)\n",
    "    P_joint = C_ij * P_m[np.newaxis, :]  # Broadcasting P(m) across rows\n",
    "    \n",
    "    # Compute marginal P(m')\n",
    "    P_m_prime = np.sum(P_joint, axis=1) # probability I interpret any given signal as m'\n",
    "    \n",
    "    # Compute mutual information using vectorized operations\n",
    "    epsilon = 1e-10\n",
    "    # Create outer product of marginals\n",
    "    P_marginal_product = np.outer(P_m_prime, P_m)\n",
    "    \n",
    "    # Compute MI: sum over all elements of P_joint * log2(P_joint / P_marginal_product)\n",
    "    # Only compute where P_joint > 0 to avoid numerical issues\n",
    "    mask = P_joint > epsilon\n",
    "    mutual_info = np.sum(\n",
    "        P_joint[mask] * np.log2(P_joint[mask] / (P_marginal_product[mask] + epsilon))\n",
    "    )\n",
    "    \n",
    "    # Normalize by entropy of M\n",
    "    if np.allclose(P_m, 1/num_messages):\n",
    "        H_M = np.log2(num_messages)\n",
    "    else:\n",
    "        H_M = -np.sum(P_m[P_m > epsilon] * np.log2(P_m[P_m > epsilon]))\n",
    "    \n",
    "    I_ij_normalized = mutual_info / H_M\n",
    "    \n",
    "    return I_ij_normalized, C_ij\n",
    "\n",
    "def mutual_info_in(E_arr, D):\n",
    "    return sum(calculate_normalized_mutual_information_vectorized(E_i, D)[0] for E_i in E_arr)\n",
    "\n",
    "def info_grad(D, E_arr, v=None):\n",
    "    \"\"\"\n",
    "    Push D in the direction of maximizing a weighted sum of mutual information from senders with \n",
    "    encoder matrices E_arr\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    D : np.ndarray  \n",
    "        Decoder matrix for agent j, shape (|M|, |S|) where D_j[m',s] = P(m'|s)\n",
    "    E_arr : list[np.ndarray] of length n\n",
    "        list of encoder matrices for agent i, shape (|S|, |M|) where E_i[s,m] = P(s|m)\n",
    "    v : np.ndarray\n",
    "        a n-vector of weights to prioritize the mutual information from different channels\n",
    "        default = 1^n\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    del_D: the update to D\n",
    "    \"\"\"\n",
    "    pass\n",
    "\n",
    "def update(D, E_arr, learning_rate=0.01):\n",
    "\n",
    "    D += learning_rate * info_grad(E_arr, D)\n",
    "\n",
    "    # normalize D here\n",
    "    \n",
    "    return D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "220f3039-75d7-450a-ac5d-7c5686b37cf9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((np.float64(0.6482589786174596),\n",
       "  array([[2.25, 0.25, 0.  ],\n",
       "         [0.25, 0.25, 0.  ],\n",
       "         [0.  , 0.  , 0.  ]])),\n",
       " (np.float64(0.6007461769407996),\n",
       "  array([[0.  , 0.  , 0.  ],\n",
       "         [0.75, 0.25, 0.  ],\n",
       "         [1.75, 0.25, 0.  ]])))"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56b55bf7-3d6b-4888-8791-0c7978848725",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "datalab",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
